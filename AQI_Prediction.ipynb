{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_city_hourly = pd.read_csv(\"dataset/city_hour.csv\")\n",
    "df_city_daily = pd.read_csv(\"dataset/city_day.csv\")\n",
    "df_station_hourly = pd.read_csv(\"dataset/station_hour.csv\")\n",
    "df_station_daily = pd.read_csv(\"dataset/station_day.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city_hourly_list = \"City,Datetime,PM2.5,PM10,NO,NO2,NOx,NH3,CO,SO2,O3,Benzene,Toluene,Xylene,AQI,AQI_Bucket\"\n",
    "df_city_daily_list = \"City,Date,PM2.5,PM10,NO,NO2,NOx,NH3,CO,SO2,O3,Benzene,Toluene,Xylene,AQI,AQI_Bucket\"\n",
    "df_station_hourly_list = \"StationId,Datetime,PM2.5,PM10,NO,NO2,NOx,NH3,CO,SO2,O3,Benzene,Toluene,Xylene,AQI,AQI_Bucket\"\n",
    "df_station_daily_list = \"StationId,Date,PM2.5,PM10,NO,NO2,NOx,NH3,CO,SO2,O3,Benzene,Toluene,Xylene,AQI,AQI_Bucket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city_hourly = df_city_hourly.drop(columns=[ 'NH3','City','Datetime','Toluene', 'Xylene', 'AQI_Bucket'], axis=1)\n",
    "df_city_daily = df_city_daily.drop(columns=[ 'NH3','City','Date','Toluene', 'Xylene', 'AQI_Bucket'], axis=1)\n",
    "df_station_hourly  = df_station_hourly.drop(columns=[ 'NH3','StationId','Datetime','Toluene', 'Xylene', 'AQI_Bucket'], axis=1)\n",
    "df_station_daily = df_station_daily.drop(columns=[ 'NH3','StationId','Date','Toluene', 'Xylene', 'AQI_Bucket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_city_hourly, df_city_daily, df_station_hourly, df_station_daily]\n",
    "df_merged = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_fill = ['PM2.5','PM10', 'NO', 'NO2', 'NOx', 'CO', 'SO2', 'O3', 'Benzene','AQI']\n",
    "df_merged[columns_to_fill] = df_merged[columns_to_fill].fillna(df_merged[columns_to_fill].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.replace([np.inf, -np.inf], np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_features = ['PM2.5','PM10', 'NO', 'NO2', 'NOx', 'CO', 'SO2', 'O3', 'Benzene']\n",
    "X = df_merged['AQI']\n",
    "y = df_merged[air_quality_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train.to_frame())\n",
    "X_test_scaled = scaler_X.transform(X_test.to_frame())\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(\"X_train_scaled stats:\")\n",
    "print(\"Mean:\", np.mean(X_train_scaled))\n",
    "print(\"Std:\", np.std(X_train_scaled))\n",
    "print(\"Min:\", np.min(X_train_scaled))\n",
    "print(\"Max:\", np.max(X_train_scaled))\n",
    "\n",
    "print(\"\\ny_train_scaled stats:\")\n",
    "print(\"Mean:\", np.mean(y_train_scaled))\n",
    "print(\"Std:\", np.std(y_train_scaled))\n",
    "print(\"Min:\", np.min(y_train_scaled))\n",
    "print(\"Max:\", np.max(y_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler_X, 'scaler_X.pkl')\n",
    "joblib.dump(scaler_y, 'scaler_y.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    return 0.001 * 0.9 ** epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "    ],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model.evaluate(X_test_scaled, y_test_scaled)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "\n",
    "scaler = joblib.load('scaler_y.pkl')\n",
    "\n",
    "user_input = pd.DataFrame({\n",
    "    'PM2.5': [81],\n",
    "    'PM10': [124],\n",
    "    'NO': [1.44],\n",
    "    'NO2': [20],\n",
    "    'NOx': [12],\n",
    "    'NH3': [10],\n",
    "    'CO': [0.1],\n",
    "    'SO2': [15],\n",
    "    'O3': [127],\n",
    "    'Benzene': [0.20],\n",
    "    'Toluene': [6],\n",
    "    'Xylene': [0.06]\n",
    "})\n",
    "\n",
    "\n",
    "user_input_scaled = scaler.transform(user_input.values.reshape(-1, 1))\n",
    "\n",
    "user_pred = model.predict(user_input_scaled)\n",
    "\n",
    "actual_pred = scaler.inverse_transform(user_pred)\n",
    "\n",
    "print(user_pred)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(actual_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
