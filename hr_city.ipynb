{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STATION HOUR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Padmajaa\\AppData\\Local\\Temp\\ipykernel_17348\\2577960979.py:1: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r'C:\\Users\\Padmajaa\\OneDrive - SSN Trust\\IIT KANPUR\\ds\\station_hour.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Padmajaa\\OneDrive - SSN Trust\\IIT KANPUR\\ds\\station_hour.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "df['Month'] = df['Datetime'].dt.month\n",
    "df['Year'] = df['Datetime'].dt.year\n",
    "df['Hour'] = df['Datetime'].dt.hour\n",
    "df['Minute'] = df['Datetime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StationId           0\n",
      "Datetime            0\n",
      "PM2.5          647689\n",
      "PM10          1119252\n",
      "NO             553711\n",
      "NO2            528973\n",
      "NOx            490808\n",
      "NH3           1236618\n",
      "CO             499302\n",
      "SO2            742737\n",
      "O3             725973\n",
      "Benzene        861579\n",
      "Toluene       1042366\n",
      "Xylene        2075104\n",
      "AQI            570190\n",
      "AQI_Bucket     570190\n",
      "Month               0\n",
      "Year                0\n",
      "Hour                0\n",
      "Minute              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['NH3', 'Toluene', 'Xylene', 'AQI', 'AQI_Bucket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_fill = ['PM2.5','PM10', 'NO', 'NO2', 'NOx', 'CO', 'SO2', 'O3', 'Benzene']\n",
    "df[columns_to_fill] = df[columns_to_fill].fillna(df[columns_to_fill].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StationId</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-24 17:00:00</td>\n",
       "      <td>60.50</td>\n",
       "      <td>98.00</td>\n",
       "      <td>2.35</td>\n",
       "      <td>30.80</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11.85</td>\n",
       "      <td>126.40</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-24 18:00:00</td>\n",
       "      <td>65.50</td>\n",
       "      <td>111.25</td>\n",
       "      <td>2.70</td>\n",
       "      <td>24.20</td>\n",
       "      <td>15.07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>13.17</td>\n",
       "      <td>117.12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-24 19:00:00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>132.00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>25.18</td>\n",
       "      <td>15.15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12.08</td>\n",
       "      <td>98.98</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-24 20:00:00</td>\n",
       "      <td>81.50</td>\n",
       "      <td>133.25</td>\n",
       "      <td>1.95</td>\n",
       "      <td>16.25</td>\n",
       "      <td>10.23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.47</td>\n",
       "      <td>112.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-24 21:00:00</td>\n",
       "      <td>75.25</td>\n",
       "      <td>116.00</td>\n",
       "      <td>1.43</td>\n",
       "      <td>17.48</td>\n",
       "      <td>10.43</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9.12</td>\n",
       "      <td>106.35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StationId            Datetime  PM2.5    PM10    NO    NO2    NOx   CO  \\\n",
       "0     AP001 2017-11-24 17:00:00  60.50   98.00  2.35  30.80  18.25  0.1   \n",
       "1     AP001 2017-11-24 18:00:00  65.50  111.25  2.70  24.20  15.07  0.1   \n",
       "2     AP001 2017-11-24 19:00:00  80.00  132.00  2.10  25.18  15.15  0.1   \n",
       "3     AP001 2017-11-24 20:00:00  81.50  133.25  1.95  16.25  10.23  0.1   \n",
       "4     AP001 2017-11-24 21:00:00  75.25  116.00  1.43  17.48  10.43  0.1   \n",
       "\n",
       "     SO2      O3  Benzene  Month  Year  Hour  Minute  \n",
       "0  11.85  126.40      0.1     11  2017    17       0  \n",
       "1  13.17  117.12      0.1     11  2017    18       0  \n",
       "2  12.08   98.98      0.2     11  2017    19       0  \n",
       "3  10.47  112.20      0.2     11  2017    20       0  \n",
       "4   9.12  106.35      0.2     11  2017    21       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features\n",
    "time_features = ['Month', 'Year', 'Hour', 'Minute']\n",
    "air_quality_features = ['PM2.5', 'NO', 'NO2', 'NOx', 'CO', 'SO2', 'O3', 'Benzene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ids = df['StationId'].unique()\n",
    "station_id_to_index = {station: index for index, station in enumerate(station_ids)}\n",
    "df['StationIdIndex'] = df['StationId'].map(station_id_to_index)\n",
    "num_stations = len(station_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StationId</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>StationIdIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-24 17:00:00</td>\n",
       "      <td>60.50</td>\n",
       "      <td>98.00</td>\n",
       "      <td>2.35</td>\n",
       "      <td>30.80</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11.85</td>\n",
       "      <td>126.40</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-24 18:00:00</td>\n",
       "      <td>65.50</td>\n",
       "      <td>111.25</td>\n",
       "      <td>2.70</td>\n",
       "      <td>24.20</td>\n",
       "      <td>15.07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>13.17</td>\n",
       "      <td>117.12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-24 19:00:00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>132.00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>25.18</td>\n",
       "      <td>15.15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12.08</td>\n",
       "      <td>98.98</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-24 20:00:00</td>\n",
       "      <td>81.50</td>\n",
       "      <td>133.25</td>\n",
       "      <td>1.95</td>\n",
       "      <td>16.25</td>\n",
       "      <td>10.23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.47</td>\n",
       "      <td>112.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-24 21:00:00</td>\n",
       "      <td>75.25</td>\n",
       "      <td>116.00</td>\n",
       "      <td>1.43</td>\n",
       "      <td>17.48</td>\n",
       "      <td>10.43</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9.12</td>\n",
       "      <td>106.35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StationId            Datetime  PM2.5    PM10    NO    NO2    NOx   CO  \\\n",
       "0     AP001 2017-11-24 17:00:00  60.50   98.00  2.35  30.80  18.25  0.1   \n",
       "1     AP001 2017-11-24 18:00:00  65.50  111.25  2.70  24.20  15.07  0.1   \n",
       "2     AP001 2017-11-24 19:00:00  80.00  132.00  2.10  25.18  15.15  0.1   \n",
       "3     AP001 2017-11-24 20:00:00  81.50  133.25  1.95  16.25  10.23  0.1   \n",
       "4     AP001 2017-11-24 21:00:00  75.25  116.00  1.43  17.48  10.43  0.1   \n",
       "\n",
       "     SO2      O3  Benzene  Month  Year  Hour  Minute  StationIdIndex  \n",
       "0  11.85  126.40      0.1     11  2017    17       0               0  \n",
       "1  13.17  117.12      0.1     11  2017    18       0               0  \n",
       "2  12.08   98.98      0.2     11  2017    19       0               0  \n",
       "3  10.47  112.20      0.2     11  2017    20       0               0  \n",
       "4   9.12  106.35      0.2     11  2017    21       0               0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def create_sequences(data, station_data, seq_length):\n",
    "    X, y, X_Station = [], [], []\n",
    "    \n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length, :])  # Sequence of features\n",
    "        y.append(data[i + seq_length, :len(features)])  # Target: next timestep pollutant values\n",
    "        X_Station.append(station_data[i + seq_length])  # station index for sequence\n",
    "        \n",
    "    return np.array(X), np.array(y), np.array(X_Station)\n",
    "\n",
    "# Sequence length\n",
    "seq_length = 30\n",
    "\n",
    "# Define the features to use for the model\n",
    "features = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'CO', 'SO2', 'O3', 'Benzene']\n",
    "\n",
    "# Extract feature values and other relevant data for sequence generation\n",
    "data = df[features + ['Month', 'Year', 'Hour', 'Minute']].values\n",
    "station_data = df['StationIdIndex'].values\n",
    "\n",
    "# Create sequences using the provided function\n",
    "X, y, X_Station = create_sequences(data, station_data, seq_length)\n",
    "\n",
    "# Convert stationIndex to categorical (for multi-station handling)\n",
    "num_stations = len(df['StationId'].unique())  # Get number of unique cities\n",
    "X_Station = to_categorical(X_Station, num_classes=num_stations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, station_data, seq_length):\n",
    "    X, y, X_Station = [], [], []\n",
    "    \n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length, :])  # Sequence of features\n",
    "        y.append(data[i + seq_length, :len(features)])  # Target: next timestep pollutant values\n",
    "        X_Station.append(station_data[i + seq_length])  # station index for sequence\n",
    "        \n",
    "    return np.array(X), np.array(y), np.array(X_Station)\n",
    "\n",
    "# Sequence length\n",
    "seq_length = 30\n",
    "\n",
    "# Define the features to use for the model\n",
    "features = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'CO', 'SO2', 'O3', 'Benzene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.88 GiB for an array with shape (2589053, 30, 13) and data type float16",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m station_data \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStationIdIndex\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Create sequences for the model (you need to implement the 'create_sequences' function as before)\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m X, y, X_station \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Convert stationIndex to one-hot encoding\u001b[39;00m\n\u001b[0;32m     62\u001b[0m num_stations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStationId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n",
      "Cell \u001b[1;32mIn[20], line 9\u001b[0m, in \u001b[0;36mcreate_sequences\u001b[1;34m(data, station_data, seq_length)\u001b[0m\n\u001b[0;32m      6\u001b[0m     y\u001b[38;5;241m.\u001b[39mappend(data[i \u001b[38;5;241m+\u001b[39m seq_length, :\u001b[38;5;28mlen\u001b[39m(features)])  \u001b[38;5;66;03m# Target: next timestep pollutant values\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     X_Station\u001b[38;5;241m.\u001b[39mappend(station_data[i \u001b[38;5;241m+\u001b[39m seq_length])  \u001b[38;5;66;03m# station index for sequence\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(X), np\u001b[38;5;241m.\u001b[39marray(y), np\u001b[38;5;241m.\u001b[39marray(X_Station)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.88 GiB for an array with shape (2589053, 30, 13) and data type float16"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Concatenate, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Define RMSE metric\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "# Create the stacked LSTM model\n",
    "def create_stacked_lstm_model(seq_length, num_features, num_stations, num_pollutants):\n",
    "    # Input for the time series sequence data\n",
    "    input_seq = Input(shape=(seq_length, num_features))  # (Batch, seq_length, num_features)\n",
    "    input_station = Input(shape=(num_stations,))  # station input as one-hot vector\n",
    "\n",
    "    # LSTM layers with recurrent dropout\n",
    "    x = LSTM(128, return_sequences=True, recurrent_dropout=0.1)(input_seq)\n",
    "    x = LSTM(64, return_sequences=False, recurrent_dropout=0.1)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # Batch Normalization\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Concatenate the output of LSTM with station input\n",
    "    x = Concatenate()([x, input_station])\n",
    "    \n",
    "    # Fully connected layers with regularization\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(32, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    \n",
    "    # Output layer for pollutant prediction\n",
    "    output = Dense(num_pollutants, activation='linear')(x)\n",
    "\n",
    "    # Create and compile the model\n",
    "    model = Model(inputs=[input_seq, input_station], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse', metrics=[rmse])\n",
    "    return model\n",
    "\n",
    "# Data preparation for the model\n",
    "seq_length = 30  # Sequence length for the LSTM\n",
    "\n",
    "# Define the features for input\n",
    "features = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'CO', 'SO2', 'O3', 'Benzene']\n",
    "num_features = len(features) + 4  # Adding 4 extra (Month, Year, Hour, Minute)\n",
    "num_pollutants = len(features)  # Number of pollutants to predict\n",
    "\n",
    "# Prepare data for sequences\n",
    "data = df[features + ['Month', 'Year', 'Hour', 'Minute']].values.astype(np.float16)\n",
    "station_data = df['StationIdIndex'].values.astype(np.int32)\n",
    "\n",
    "# Create sequences for the model (you need to implement the 'create_sequences' function as before)\n",
    "X, y, X_station = create_sequences(data, station_data, seq_length)\n",
    "\n",
    "# Convert stationIndex to one-hot encoding\n",
    "num_stations = len(df['StationId'].unique())\n",
    "X_station = to_categorical(X_station, num_classes=num_stations)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test, X_station_train, X_station_test = train_test_split(\n",
    "    X, y, X_station, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create the model\n",
    "model = create_stacked_lstm_model(seq_length, num_features, num_stations, num_pollutants)\n",
    "\n",
    "# Callbacks for early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "def data_generator(X, X_station, y, batch_size):\n",
    "    while True:\n",
    "        for start in range(0, len(X), batch_size):\n",
    "            end = min(start + batch_size, len(X))\n",
    "            yield [X[start:end], X_station[start:end]], y[start:end]\n",
    "\n",
    "batch_size = 16\n",
    "train_gen = data_generator(X_train, X_station_train, y_train, batch_size)\n",
    "val_gen = data_generator(X_test, X_station_test, y_test, batch_size)\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=len(X_test) // batch_size,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping, lr_scheduler],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predict pollutant concentrations\n",
    "def predict_pollutants(model, X, X_station):\n",
    "    predictions = model.predict([X, X_station])\n",
    "    return predictions\n",
    "\n",
    "# Example prediction call\n",
    "predicted_pollutants = predict_pollutants(model, X_test, X_station_test)\n",
    "print(predicted_pollutants[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('C_hr.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('C_hr.h5', custom_objects={'mse': 'mean_squared_error'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "c:\\Users\\sunha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['input_layer_4', 'input_layer_5']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708ms/step\n",
      "Predicted pollutant concentrations for Chennai on 2025-10-05 00:00:00:\n",
      "PM2.5: 22.75\n",
      "PM10: 37.74\n",
      "NO: 5.78\n",
      "NO2: 14.95\n",
      "NOx: 14.78\n",
      "CO: 1.07\n",
      "SO2: 7.63\n",
      "O3: 46.62\n",
      "Benzene: 0.46\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model with custom metrics\n",
    "model = load_model('C_hr.h5', custom_objects={'mse': 'mean_squared_error'})\n",
    "\n",
    "# Function to predict pollutants for a future date and city\n",
    "def predict_pollutants_for_date(model, future_date, city, seq_length, features, city_to_index):\n",
    "    # Check if the required historical data is available\n",
    "    historical_data = df[df['City'] == city].tail(seq_length)  # Get the last 'seq_length' rows for that city\n",
    "    \n",
    "    if len(historical_data) < seq_length:\n",
    "        print(f\"Not enough historical data for city: {city} to predict for {future_date}.\")\n",
    "        return\n",
    "    \n",
    "    # Prepare the sequence input and city input\n",
    "    sequence_input = historical_data[features + ['Month', 'Year', 'Hour', 'Minute']].values\n",
    "    \n",
    "    # Normalize or reshape the sequence data if necessary\n",
    "    X_input = np.array([sequence_input])  # Reshape to (1, seq_length, num_features)\n",
    "    \n",
    "    # One-hot encode the city index for the city input\n",
    "    city_index = city_to_index[city]\n",
    "    X_city_input = np.zeros((1, len(city_to_index)))\n",
    "    X_city_input[0, city_index] = 1  # One-hot encode the city index\n",
    "    \n",
    "    # Make predictions using the loaded model\n",
    "    predicted_pollutants = model.predict([X_input, X_city_input])\n",
    "\n",
    "    # Display the predicted concentrations\n",
    "    print(f\"Predicted pollutant concentrations for {city} on {future_date}:\")\n",
    "    pollutants = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'CO', 'SO2', 'O3', 'Benzene']\n",
    "    for pollutant, concentration in zip(pollutants, predicted_pollutants[0]):\n",
    "        print(f\"{pollutant}: {concentration:.2f}\")\n",
    "\n",
    "# Example usage\n",
    "future_date = pd.Timestamp('2025-10-05')\n",
    "city = 'Chennai'\n",
    "\n",
    "# Create a mapping from city names to their indices (one-hot encoding)\n",
    "city_to_index = {city_name: index for index, city_name in enumerate(df['City'].unique())}\n",
    "\n",
    "# Features used in the prediction\n",
    "features = ['PM2.5','PM10', 'NO', 'NO2', 'NOx', 'CO', 'SO2', 'O3', 'Benzene']\n",
    "seq_length = 30  # Adjust according to your model's input requirement\n",
    "\n",
    "predict_pollutants_for_date(model, future_date, city, seq_length, features, city_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4425/4425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 26ms/step\n",
      "F1 Score: 0.9636505278760298\n",
      "Root Mean Squared Error (RMSE): 17.609840010990577\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Define RMSE metric\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "# Define MSE metric\n",
    "def mse(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))\n",
    "\n",
    "# Load the saved model with custom metrics\n",
    "model = load_model('C_hr.h5', custom_objects={'rmse': rmse, 'mse': mse})\n",
    "\n",
    "# Get predictions on the test set\n",
    "predicted_pollutants = model.predict([X_test, X_city_test])\n",
    "\n",
    "# Binarize predictions and true values based on a threshold (e.g., > 0)\n",
    "threshold = 0.5  # Adjust threshold as needed\n",
    "predicted_classes = (predicted_pollutants > threshold).astype(int)\n",
    "true_classes = (y_test > threshold).astype(int)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_scores = f1_score(true_classes, predicted_classes, average='weighted', zero_division=0)\n",
    "print(f\"F1 Score: {f1_scores}\")\n",
    "\n",
    "# Calculate RMSE for additional evaluation\n",
    "rmse_value = np.sqrt(mean_squared_error(y_test, predicted_pollutants))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
