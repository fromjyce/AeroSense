{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CITY HOUR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('city_hour.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "df['Month'] = df['Datetime'].dt.month\n",
    "df['Year'] = df['Datetime'].dt.year\n",
    "df['Hour'] = df['Datetime'].dt.hour\n",
    "df['Minute'] = df['Datetime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City               0\n",
      "Datetime           0\n",
      "PM2.5         145088\n",
      "PM10          296737\n",
      "NO            116632\n",
      "NO2           117122\n",
      "NOx           123224\n",
      "NH3           272542\n",
      "CO             86517\n",
      "SO2           130373\n",
      "O3            129208\n",
      "Benzene       163646\n",
      "Toluene       220607\n",
      "Xylene        455829\n",
      "AQI           129080\n",
      "AQI_Bucket    129080\n",
      "Month              0\n",
      "Year               0\n",
      "Hour               0\n",
      "Minute             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['NH3', 'Toluene', 'Xylene', 'AQI', 'AQI_Bucket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_fill = ['PM2.5','PM10', 'NO', 'NO2', 'NOx', 'CO', 'SO2', 'O3', 'Benzene']\n",
    "df[columns_to_fill] = df[columns_to_fill].fillna(df[columns_to_fill].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>67.622994</td>\n",
       "      <td>119.075804</td>\n",
       "      <td>1.00</td>\n",
       "      <td>40.01</td>\n",
       "      <td>36.37</td>\n",
       "      <td>1.00</td>\n",
       "      <td>122.07</td>\n",
       "      <td>34.798979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>67.622994</td>\n",
       "      <td>119.075804</td>\n",
       "      <td>0.02</td>\n",
       "      <td>27.75</td>\n",
       "      <td>19.73</td>\n",
       "      <td>0.02</td>\n",
       "      <td>85.90</td>\n",
       "      <td>34.798979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>67.622994</td>\n",
       "      <td>119.075804</td>\n",
       "      <td>0.08</td>\n",
       "      <td>19.32</td>\n",
       "      <td>11.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>52.83</td>\n",
       "      <td>34.798979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>67.622994</td>\n",
       "      <td>119.075804</td>\n",
       "      <td>0.30</td>\n",
       "      <td>16.45</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>39.53</td>\n",
       "      <td>153.580000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-01 05:00:00</td>\n",
       "      <td>67.622994</td>\n",
       "      <td>119.075804</td>\n",
       "      <td>0.12</td>\n",
       "      <td>14.90</td>\n",
       "      <td>7.85</td>\n",
       "      <td>0.12</td>\n",
       "      <td>32.63</td>\n",
       "      <td>34.798979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City            Datetime      PM2.5        PM10    NO    NO2    NOx   \n",
       "0  Ahmedabad 2015-01-01 01:00:00  67.622994  119.075804  1.00  40.01  36.37  \\\n",
       "1  Ahmedabad 2015-01-01 02:00:00  67.622994  119.075804  0.02  27.75  19.73   \n",
       "2  Ahmedabad 2015-01-01 03:00:00  67.622994  119.075804  0.08  19.32  11.08   \n",
       "3  Ahmedabad 2015-01-01 04:00:00  67.622994  119.075804  0.30  16.45   9.20   \n",
       "4  Ahmedabad 2015-01-01 05:00:00  67.622994  119.075804  0.12  14.90   7.85   \n",
       "\n",
       "     CO     SO2          O3  Benzene  Month  Year  Hour  Minute  \n",
       "0  1.00  122.07   34.798979      0.0      1  2015     1       0  \n",
       "1  0.02   85.90   34.798979      0.0      1  2015     2       0  \n",
       "2  0.08   52.83   34.798979      0.0      1  2015     3       0  \n",
       "3  0.30   39.53  153.580000      0.0      1  2015     4       0  \n",
       "4  0.12   32.63   34.798979      0.0      1  2015     5       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features\n",
    "time_features = ['Month', 'Year', 'Hour', 'Minute']\n",
    "air_quality_features = ['PM2.5', 'NO', 'NO2', 'NOx', 'CO', 'SO2', 'O3', 'Benzene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = df['City'].unique()\n",
    "cities_to_index = {city: index for index, city in enumerate(cities)}\n",
    "df['CityIndex'] = df['City'].map(cities_to_index)\n",
    "num_cities= len(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>CityIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>67.622994</td>\n",
       "      <td>119.075804</td>\n",
       "      <td>1.00</td>\n",
       "      <td>40.01</td>\n",
       "      <td>36.37</td>\n",
       "      <td>1.00</td>\n",
       "      <td>122.07</td>\n",
       "      <td>34.798979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>67.622994</td>\n",
       "      <td>119.075804</td>\n",
       "      <td>0.02</td>\n",
       "      <td>27.75</td>\n",
       "      <td>19.73</td>\n",
       "      <td>0.02</td>\n",
       "      <td>85.90</td>\n",
       "      <td>34.798979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>67.622994</td>\n",
       "      <td>119.075804</td>\n",
       "      <td>0.08</td>\n",
       "      <td>19.32</td>\n",
       "      <td>11.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>52.83</td>\n",
       "      <td>34.798979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>67.622994</td>\n",
       "      <td>119.075804</td>\n",
       "      <td>0.30</td>\n",
       "      <td>16.45</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>39.53</td>\n",
       "      <td>153.580000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-01 05:00:00</td>\n",
       "      <td>67.622994</td>\n",
       "      <td>119.075804</td>\n",
       "      <td>0.12</td>\n",
       "      <td>14.90</td>\n",
       "      <td>7.85</td>\n",
       "      <td>0.12</td>\n",
       "      <td>32.63</td>\n",
       "      <td>34.798979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City            Datetime      PM2.5        PM10    NO    NO2    NOx   \n",
       "0  Ahmedabad 2015-01-01 01:00:00  67.622994  119.075804  1.00  40.01  36.37  \\\n",
       "1  Ahmedabad 2015-01-01 02:00:00  67.622994  119.075804  0.02  27.75  19.73   \n",
       "2  Ahmedabad 2015-01-01 03:00:00  67.622994  119.075804  0.08  19.32  11.08   \n",
       "3  Ahmedabad 2015-01-01 04:00:00  67.622994  119.075804  0.30  16.45   9.20   \n",
       "4  Ahmedabad 2015-01-01 05:00:00  67.622994  119.075804  0.12  14.90   7.85   \n",
       "\n",
       "     CO     SO2          O3  Benzene  Month  Year  Hour  Minute  CityIndex  \n",
       "0  1.00  122.07   34.798979      0.0      1  2015     1       0          0  \n",
       "1  0.02   85.90   34.798979      0.0      1  2015     2       0          0  \n",
       "2  0.08   52.83   34.798979      0.0      1  2015     3       0          0  \n",
       "3  0.30   39.53  153.580000      0.0      1  2015     4       0          0  \n",
       "4  0.12   32.63   34.798979      0.0      1  2015     5       0          0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (566276, 30, 13), y_train shape: (566276, 9), X_city_train shape: (566276, 26)\n",
      "X_test shape: (141569, 30, 13), y_test shape: (141569, 9), X_city_test shape: (141569, 26)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def create_sequences(data, city_data, seq_length):\n",
    "    X, y, X_city = [], [], []\n",
    "    \n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length, :])  # Sequence of features\n",
    "        y.append(data[i + seq_length, :len(features)])  # Target: next timestep pollutant values\n",
    "        X_city.append(city_data[i + seq_length])  # City index for sequence\n",
    "        \n",
    "    return np.array(X), np.array(y), np.array(X_city)\n",
    "\n",
    "# Sequence length\n",
    "seq_length = 30\n",
    "\n",
    "# Define the features to use for the model\n",
    "features = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'CO', 'SO2', 'O3', 'Benzene']\n",
    "\n",
    "# Extract feature values and other relevant data for sequence generation\n",
    "data = df[features + ['Month', 'Year', 'Hour', 'Minute']].values\n",
    "city_data = df['CityIndex'].values\n",
    "\n",
    "# Create sequences using the provided function\n",
    "X, y, X_city = create_sequences(data, city_data, seq_length)\n",
    "\n",
    "# Convert CityIndex to categorical (for multi-city handling)\n",
    "num_cities = len(df['City'].unique())  # Get number of unique cities\n",
    "X_city = to_categorical(X_city, num_classes=num_cities)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test, X_city_train, X_city_test = train_test_split(\n",
    "    X, y, X_city, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Display the shapes of the datasets for verification\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}, X_city_train shape: {X_city_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}, X_city_test shape: {X_city_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sunha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_22', 'keras_tensor_23']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 19ms/step - loss: 878.5266 - rmse: 27.3768 - val_loss: 441.2382 - val_rmse: 19.4508 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 19ms/step - loss: 499.6494 - rmse: 21.0599 - val_loss: 420.6554 - val_rmse: 19.1074 - learning_rate: 5.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 19ms/step - loss: 477.5233 - rmse: 20.5305 - val_loss: 484.9495 - val_rmse: 20.8457 - learning_rate: 5.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 19ms/step - loss: 465.7923 - rmse: 20.3056 - val_loss: 412.3201 - val_rmse: 18.8537 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 20ms/step - loss: 470.3163 - rmse: 20.3705 - val_loss: 394.7694 - val_rmse: 18.4006 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 20ms/step - loss: 454.5612 - rmse: 20.0372 - val_loss: 399.7375 - val_rmse: 18.6811 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 20ms/step - loss: 448.7482 - rmse: 19.8653 - val_loss: 421.8387 - val_rmse: 19.2945 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 20ms/step - loss: 447.2748 - rmse: 19.8440 - val_loss: 391.7700 - val_rmse: 18.3393 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 20ms/step - loss: 439.8714 - rmse: 19.6464 - val_loss: 367.1642 - val_rmse: 17.6622 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 20ms/step - loss: 434.0911 - rmse: 19.5413 - val_loss: 363.5170 - val_rmse: 17.5571 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 20ms/step - loss: 435.2194 - rmse: 19.5771 - val_loss: 390.0011 - val_rmse: 18.3729 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 20ms/step - loss: 431.2859 - rmse: 19.4682 - val_loss: 358.0524 - val_rmse: 17.3676 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 20ms/step - loss: 425.4641 - rmse: 19.3477 - val_loss: 368.5258 - val_rmse: 17.7640 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 20ms/step - loss: 427.3470 - rmse: 19.3567 - val_loss: 370.8449 - val_rmse: 17.8169 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 20ms/step - loss: 419.6152 - rmse: 19.1784 - val_loss: 366.8090 - val_rmse: 17.7027 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 21ms/step - loss: 416.2499 - rmse: 19.0783 - val_loss: 356.8434 - val_rmse: 17.4087 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1006s\u001b[0m 57ms/step - loss: 416.5468 - rmse: 19.0790 - val_loss: 349.8201 - val_rmse: 17.1861 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1006s\u001b[0m 57ms/step - loss: 408.7402 - rmse: 18.9200 - val_loss: 397.4893 - val_rmse: 18.5784 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m920s\u001b[0m 52ms/step - loss: 411.0443 - rmse: 18.9426 - val_loss: 368.8292 - val_rmse: 17.7469 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 21ms/step - loss: 409.6524 - rmse: 18.9151 - val_loss: 357.8601 - val_rmse: 17.4179 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 24ms/step - loss: 405.5379 - rmse: 18.8525 - val_loss: 373.8202 - val_rmse: 17.9206 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 26ms/step - loss: 412.0298 - rmse: 18.9154 - val_loss: 354.8184 - val_rmse: 17.3327 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m482s\u001b[0m 27ms/step - loss: 394.3526 - rmse: 18.4989 - val_loss: 342.8459 - val_rmse: 16.9221 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m807s\u001b[0m 46ms/step - loss: 389.7722 - rmse: 18.3954 - val_loss: 335.6788 - val_rmse: 16.7586 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1021s\u001b[0m 58ms/step - loss: 384.6622 - rmse: 18.2980 - val_loss: 343.7946 - val_rmse: 16.9083 - learning_rate: 2.5000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m738s\u001b[0m 42ms/step - loss: 385.6320 - rmse: 18.2681 - val_loss: 335.7769 - val_rmse: 16.7375 - learning_rate: 2.5000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 20ms/step - loss: 383.2569 - rmse: 18.2382 - val_loss: 354.1261 - val_rmse: 17.3047 - learning_rate: 2.5000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 21ms/step - loss: 387.8847 - rmse: 18.3252 - val_loss: 333.7900 - val_rmse: 16.6895 - learning_rate: 2.5000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 22ms/step - loss: 378.5081 - rmse: 18.1590 - val_loss: 353.5024 - val_rmse: 17.2902 - learning_rate: 2.5000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 22ms/step - loss: 380.7532 - rmse: 18.1858 - val_loss: 355.3694 - val_rmse: 17.4040 - learning_rate: 2.5000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 22ms/step - loss: 382.5099 - rmse: 18.1845 - val_loss: 335.8178 - val_rmse: 16.7605 - learning_rate: 2.5000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 23ms/step - loss: 381.3297 - rmse: 18.1404 - val_loss: 343.8489 - val_rmse: 16.9455 - learning_rate: 2.5000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 23ms/step - loss: 381.6935 - rmse: 18.1750 - val_loss: 341.8059 - val_rmse: 16.9443 - learning_rate: 2.5000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 23ms/step - loss: 376.6564 - rmse: 18.0277 - val_loss: 330.0339 - val_rmse: 16.5871 - learning_rate: 1.2500e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 23ms/step - loss: 375.5082 - rmse: 17.9662 - val_loss: 331.2518 - val_rmse: 16.5936 - learning_rate: 1.2500e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 23ms/step - loss: 371.1952 - rmse: 17.9106 - val_loss: 331.5551 - val_rmse: 16.6116 - learning_rate: 1.2500e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 23ms/step - loss: 374.0822 - rmse: 17.9455 - val_loss: 335.1055 - val_rmse: 16.7517 - learning_rate: 1.2500e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 23ms/step - loss: 372.3632 - rmse: 17.9157 - val_loss: 326.5021 - val_rmse: 16.4676 - learning_rate: 1.2500e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 23ms/step - loss: 377.8805 - rmse: 17.9962 - val_loss: 328.9163 - val_rmse: 16.5012 - learning_rate: 1.2500e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 23ms/step - loss: 373.0778 - rmse: 17.9291 - val_loss: 324.3864 - val_rmse: 16.3533 - learning_rate: 1.2500e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 23ms/step - loss: 367.9595 - rmse: 17.8078 - val_loss: 337.9886 - val_rmse: 16.8261 - learning_rate: 1.2500e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 23ms/step - loss: 368.4596 - rmse: 17.7935 - val_loss: 328.2612 - val_rmse: 16.5554 - learning_rate: 1.2500e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 23ms/step - loss: 372.4990 - rmse: 17.8802 - val_loss: 320.4837 - val_rmse: 16.2816 - learning_rate: 1.2500e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 23ms/step - loss: 366.8547 - rmse: 17.7879 - val_loss: 327.2470 - val_rmse: 16.5011 - learning_rate: 1.2500e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 23ms/step - loss: 368.3344 - rmse: 17.8030 - val_loss: 322.6561 - val_rmse: 16.3351 - learning_rate: 1.2500e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 23ms/step - loss: 366.8542 - rmse: 17.7903 - val_loss: 354.1887 - val_rmse: 17.4099 - learning_rate: 1.2500e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 23ms/step - loss: 373.9110 - rmse: 17.8907 - val_loss: 324.2966 - val_rmse: 16.3965 - learning_rate: 1.2500e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 23ms/step - loss: 368.8893 - rmse: 17.7922 - val_loss: 325.8379 - val_rmse: 16.4664 - learning_rate: 1.2500e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 23ms/step - loss: 361.7729 - rmse: 17.6622 - val_loss: 318.6980 - val_rmse: 16.1840 - learning_rate: 6.2500e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 24ms/step - loss: 361.8814 - rmse: 17.6638 - val_loss: 319.8506 - val_rmse: 16.2586 - learning_rate: 6.2500e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 24ms/step - loss: 363.6733 - rmse: 17.6488 - val_loss: 320.3282 - val_rmse: 16.2697 - learning_rate: 6.2500e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 24ms/step - loss: 363.2006 - rmse: 17.6365 - val_loss: 334.8328 - val_rmse: 16.7502 - learning_rate: 6.2500e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 24ms/step - loss: 366.9768 - rmse: 17.7179 - val_loss: 322.3720 - val_rmse: 16.3287 - learning_rate: 6.2500e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 24ms/step - loss: 360.5491 - rmse: 17.6011 - val_loss: 320.3939 - val_rmse: 16.2499 - learning_rate: 6.2500e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 24ms/step - loss: 358.7794 - rmse: 17.4996 - val_loss: 319.9437 - val_rmse: 16.2386 - learning_rate: 3.1250e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 24ms/step - loss: 357.3850 - rmse: 17.5418 - val_loss: 314.9379 - val_rmse: 16.0936 - learning_rate: 3.1250e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 24ms/step - loss: 353.5121 - rmse: 17.4478 - val_loss: 316.2976 - val_rmse: 16.1426 - learning_rate: 3.1250e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 24ms/step - loss: 355.1360 - rmse: 17.4912 - val_loss: 319.4803 - val_rmse: 16.2461 - learning_rate: 3.1250e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 24ms/step - loss: 359.2551 - rmse: 17.5888 - val_loss: 321.0056 - val_rmse: 16.2750 - learning_rate: 3.1250e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 24ms/step - loss: 359.3188 - rmse: 17.5738 - val_loss: 315.8746 - val_rmse: 16.1156 - learning_rate: 3.1250e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 24ms/step - loss: 361.9485 - rmse: 17.5646 - val_loss: 316.3007 - val_rmse: 16.1235 - learning_rate: 3.1250e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 24ms/step - loss: 355.4210 - rmse: 17.4716 - val_loss: 313.8710 - val_rmse: 16.0421 - learning_rate: 1.5625e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 24ms/step - loss: 356.5786 - rmse: 17.5051 - val_loss: 314.8432 - val_rmse: 16.0850 - learning_rate: 1.5625e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 24ms/step - loss: 358.9596 - rmse: 17.5276 - val_loss: 315.7387 - val_rmse: 16.1159 - learning_rate: 1.5625e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 24ms/step - loss: 353.9080 - rmse: 17.4477 - val_loss: 314.3205 - val_rmse: 16.0834 - learning_rate: 1.5625e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 24ms/step - loss: 360.6653 - rmse: 17.5481 - val_loss: 313.2942 - val_rmse: 16.0319 - learning_rate: 1.5625e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 24ms/step - loss: 352.9563 - rmse: 17.4279 - val_loss: 314.4236 - val_rmse: 16.0791 - learning_rate: 1.5625e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 24ms/step - loss: 357.6357 - rmse: 17.4991 - val_loss: 313.0223 - val_rmse: 16.0314 - learning_rate: 1.5625e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 25ms/step - loss: 354.9021 - rmse: 17.4556 - val_loss: 312.8929 - val_rmse: 16.0219 - learning_rate: 1.5625e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 24ms/step - loss: 360.8716 - rmse: 17.5344 - val_loss: 314.9589 - val_rmse: 16.1015 - learning_rate: 1.5625e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 24ms/step - loss: 355.7592 - rmse: 17.4596 - val_loss: 315.8754 - val_rmse: 16.1303 - learning_rate: 1.5625e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 24ms/step - loss: 359.1184 - rmse: 17.5064 - val_loss: 314.5931 - val_rmse: 16.0753 - learning_rate: 1.5625e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 25ms/step - loss: 356.4023 - rmse: 17.4605 - val_loss: 314.8338 - val_rmse: 16.0836 - learning_rate: 1.5625e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 25ms/step - loss: 361.4256 - rmse: 17.5662 - val_loss: 314.9161 - val_rmse: 16.0947 - learning_rate: 1.5625e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 25ms/step - loss: 358.8975 - rmse: 17.4762 - val_loss: 312.7434 - val_rmse: 16.0061 - learning_rate: 7.8125e-06\n",
      "Epoch 76/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 25ms/step - loss: 355.9665 - rmse: 17.4832 - val_loss: 313.7906 - val_rmse: 16.0471 - learning_rate: 7.8125e-06\n",
      "Epoch 77/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 25ms/step - loss: 357.5357 - rmse: 17.4600 - val_loss: 313.1186 - val_rmse: 16.0284 - learning_rate: 7.8125e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 25ms/step - loss: 356.3218 - rmse: 17.4718 - val_loss: 312.5611 - val_rmse: 16.0085 - learning_rate: 7.8125e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 25ms/step - loss: 353.3588 - rmse: 17.4380 - val_loss: 313.4633 - val_rmse: 16.0279 - learning_rate: 7.8125e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 25ms/step - loss: 356.0092 - rmse: 17.4533 - val_loss: 313.2387 - val_rmse: 16.0352 - learning_rate: 7.8125e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 25ms/step - loss: 350.2367 - rmse: 17.3534 - val_loss: 313.0977 - val_rmse: 16.0214 - learning_rate: 7.8125e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 25ms/step - loss: 350.3550 - rmse: 17.3653 - val_loss: 313.8661 - val_rmse: 16.0453 - learning_rate: 7.8125e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 26ms/step - loss: 351.7150 - rmse: 17.3470 - val_loss: 312.7091 - val_rmse: 16.0108 - learning_rate: 7.8125e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 26ms/step - loss: 355.1393 - rmse: 17.4265 - val_loss: 313.0536 - val_rmse: 16.0218 - learning_rate: 3.9063e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 26ms/step - loss: 355.9772 - rmse: 17.4616 - val_loss: 312.3353 - val_rmse: 15.9991 - learning_rate: 3.9063e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 26ms/step - loss: 354.4953 - rmse: 17.4228 - val_loss: 312.8365 - val_rmse: 16.0179 - learning_rate: 3.9063e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 26ms/step - loss: 354.0604 - rmse: 17.4149 - val_loss: 312.5165 - val_rmse: 16.0082 - learning_rate: 3.9063e-06\n",
      "Epoch 88/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 26ms/step - loss: 355.4586 - rmse: 17.4516 - val_loss: 312.6067 - val_rmse: 16.0022 - learning_rate: 3.9063e-06\n",
      "Epoch 89/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 26ms/step - loss: 357.7616 - rmse: 17.4808 - val_loss: 312.5966 - val_rmse: 16.0059 - learning_rate: 3.9063e-06\n",
      "Epoch 90/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 26ms/step - loss: 356.0362 - rmse: 17.4535 - val_loss: 312.5117 - val_rmse: 16.0001 - learning_rate: 3.9063e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 26ms/step - loss: 360.7033 - rmse: 17.5354 - val_loss: 312.2699 - val_rmse: 15.9931 - learning_rate: 1.9531e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 23ms/step - loss: 356.4438 - rmse: 17.4286 - val_loss: 312.3109 - val_rmse: 16.0019 - learning_rate: 1.9531e-06\n",
      "Epoch 93/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 23ms/step - loss: 352.7672 - rmse: 17.3833 - val_loss: 312.4927 - val_rmse: 16.0080 - learning_rate: 1.9531e-06\n",
      "Epoch 94/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 23ms/step - loss: 354.1342 - rmse: 17.3831 - val_loss: 312.2816 - val_rmse: 15.9980 - learning_rate: 1.9531e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 23ms/step - loss: 358.8707 - rmse: 17.5056 - val_loss: 312.2356 - val_rmse: 15.9987 - learning_rate: 1.9531e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 23ms/step - loss: 350.7127 - rmse: 17.3967 - val_loss: 312.0629 - val_rmse: 15.9903 - learning_rate: 1.9531e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 24ms/step - loss: 355.9330 - rmse: 17.4572 - val_loss: 311.8468 - val_rmse: 15.9815 - learning_rate: 1.9531e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1099s\u001b[0m 62ms/step - loss: 355.6018 - rmse: 17.4306 - val_loss: 312.3919 - val_rmse: 16.0053 - learning_rate: 1.9531e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1249s\u001b[0m 71ms/step - loss: 359.2917 - rmse: 17.4880 - val_loss: 311.7301 - val_rmse: 15.9815 - learning_rate: 1.9531e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m17697/17697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1045s\u001b[0m 59ms/step - loss: 360.5732 - rmse: 17.5111 - val_loss: 312.7057 - val_rmse: 16.0127 - learning_rate: 1.9531e-06\n",
      "\u001b[1m4425/4425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 25ms/step\n",
      "[[ 58.95556    115.60697     15.816345    22.67083     30.02304\n",
      "    0.98263216  12.153001    32.737503     2.3735242 ]\n",
      " [ 66.02117    119.28552     18.67326     51.525394    43.8785\n",
      "    1.1219411    7.544641    19.58522      3.065344  ]\n",
      " [112.10448    104.12601    229.83319     73.23366    205.72289\n",
      "   24.129057    23.06037      3.1652906    9.549061  ]\n",
      " [174.78653    122.22151      8.721471    42.066994    27.865194\n",
      "    1.9495997    9.653913    52.35099      2.5035675 ]\n",
      " [ 73.00153    120.99784     12.491722    28.042141    22.118267\n",
      "    3.716405    59.149143    42.394745     3.4487708 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Concatenate, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Define RMSE metric\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "# Create the stacked LSTM model\n",
    "def create_stacked_lstm_model(seq_length, num_features, num_cities, num_pollutants):\n",
    "    # Input for the time series sequence data\n",
    "    input_seq = Input(shape=(seq_length, num_features))  # (Batch, seq_length, num_features)\n",
    "    input_city = Input(shape=(num_cities,))  # City input as one-hot vector\n",
    "\n",
    "    # LSTM layers with recurrent dropout\n",
    "    x = LSTM(128, return_sequences=True, recurrent_dropout=0.1)(input_seq)\n",
    "    x = LSTM(64, return_sequences=False, recurrent_dropout=0.1)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # Batch Normalization\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Concatenate the output of LSTM with city input\n",
    "    x = Concatenate()([x, input_city])\n",
    "    \n",
    "    # Fully connected layers with regularization\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(32, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    \n",
    "    # Output layer for pollutant prediction\n",
    "    output = Dense(num_pollutants, activation='linear')(x)\n",
    "\n",
    "    # Create and compile the model\n",
    "    model = Model(inputs=[input_seq, input_city], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse', metrics=[rmse])\n",
    "    return model\n",
    "\n",
    "# Data preparation for the model\n",
    "seq_length = 30  # Sequence length for the LSTM\n",
    "\n",
    "# Define the features for input\n",
    "features = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'CO', 'SO2', 'O3', 'Benzene']\n",
    "num_features = len(features) + 4  # Adding 4 extra (Month, Year, Hour, Minute)\n",
    "num_pollutants = len(features)  # Number of pollutants to predict\n",
    "\n",
    "# Prepare data for sequences\n",
    "data = df[features + ['Month', 'Year', 'Hour', 'Minute']].values\n",
    "city_data = df['CityIndex'].values\n",
    "\n",
    "# Create sequences for the model\n",
    "X, y, X_city = create_sequences(data, city_data, seq_length)\n",
    "\n",
    "# Convert CityIndex to one-hot encoding\n",
    "num_cities = len(df['City'].unique())\n",
    "X_city = to_categorical(X_city, num_classes=num_cities)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test, X_city_train, X_city_test = train_test_split(\n",
    "    X, y, X_city, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create the model\n",
    "model = create_stacked_lstm_model(seq_length, num_features, num_cities, num_pollutants)\n",
    "\n",
    "# Callbacks for early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_train, X_city_train], y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=([X_test, X_city_test], y_test),\n",
    "    callbacks=[early_stopping, lr_scheduler],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predict pollutant concentrations\n",
    "def predict_pollutants(model, X, X_city):\n",
    "    predictions = model.predict([X, X_city])\n",
    "    return predictions\n",
    "\n",
    "# Example prediction call\n",
    "predicted_pollutants = predict_pollutants(model, X_test, X_city_test)\n",
    "print(predicted_pollutants[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('C_hr.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('C_hr.h5', custom_objects={'mse': 'mean_squared_error'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "c:\\Users\\sunha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['input_layer_4', 'input_layer_5']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708ms/step\n",
      "Predicted pollutant concentrations for Chennai on 2025-10-05 00:00:00:\n",
      "PM2.5: 22.75\n",
      "PM10: 37.74\n",
      "NO: 5.78\n",
      "NO2: 14.95\n",
      "NOx: 14.78\n",
      "CO: 1.07\n",
      "SO2: 7.63\n",
      "O3: 46.62\n",
      "Benzene: 0.46\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model with custom metrics\n",
    "model = load_model('C_hr.h5', custom_objects={'mse': 'mean_squared_error'})\n",
    "\n",
    "# Function to predict pollutants for a future date and city\n",
    "def predict_pollutants_for_date(model, future_date, city, seq_length, features, city_to_index):\n",
    "    # Check if the required historical data is available\n",
    "    historical_data = df[df['City'] == city].tail(seq_length)  # Get the last 'seq_length' rows for that city\n",
    "    \n",
    "    if len(historical_data) < seq_length:\n",
    "        print(f\"Not enough historical data for city: {city} to predict for {future_date}.\")\n",
    "        return\n",
    "    \n",
    "    # Prepare the sequence input and city input\n",
    "    sequence_input = historical_data[features + ['Month', 'Year', 'Hour', 'Minute']].values\n",
    "    \n",
    "    # Normalize or reshape the sequence data if necessary\n",
    "    X_input = np.array([sequence_input])  # Reshape to (1, seq_length, num_features)\n",
    "    \n",
    "    # One-hot encode the city index for the city input\n",
    "    city_index = city_to_index[city]\n",
    "    X_city_input = np.zeros((1, len(city_to_index)))\n",
    "    X_city_input[0, city_index] = 1  # One-hot encode the city index\n",
    "    \n",
    "    # Make predictions using the loaded model\n",
    "    predicted_pollutants = model.predict([X_input, X_city_input])\n",
    "\n",
    "    # Display the predicted concentrations\n",
    "    print(f\"Predicted pollutant concentrations for {city} on {future_date}:\")\n",
    "    pollutants = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'CO', 'SO2', 'O3', 'Benzene']\n",
    "    for pollutant, concentration in zip(pollutants, predicted_pollutants[0]):\n",
    "        print(f\"{pollutant}: {concentration:.2f}\")\n",
    "\n",
    "# Example usage\n",
    "future_date = pd.Timestamp('2025-10-05')\n",
    "city = 'Chennai'\n",
    "\n",
    "# Create a mapping from city names to their indices (one-hot encoding)\n",
    "city_to_index = {city_name: index for index, city_name in enumerate(df['City'].unique())}\n",
    "\n",
    "# Features used in the prediction\n",
    "features = ['PM2.5','PM10', 'NO', 'NO2', 'NOx', 'CO', 'SO2', 'O3', 'Benzene']\n",
    "seq_length = 30  # Adjust according to your model's input requirement\n",
    "\n",
    "predict_pollutants_for_date(model, future_date, city, seq_length, features, city_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4425/4425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 26ms/step\n",
      "F1 Score: 0.9636505278760298\n",
      "Root Mean Squared Error (RMSE): 17.609840010990577\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Define RMSE metric\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "# Define MSE metric\n",
    "def mse(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))\n",
    "\n",
    "# Load the saved model with custom metrics\n",
    "model = load_model('C_hr.h5', custom_objects={'rmse': rmse, 'mse': mse})\n",
    "\n",
    "# Get predictions on the test set\n",
    "predicted_pollutants = model.predict([X_test, X_city_test])\n",
    "\n",
    "# Binarize predictions and true values based on a threshold (e.g., > 0)\n",
    "threshold = 0.5  # Adjust threshold as needed\n",
    "predicted_classes = (predicted_pollutants > threshold).astype(int)\n",
    "true_classes = (y_test > threshold).astype(int)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_scores = f1_score(true_classes, predicted_classes, average='weighted', zero_division=0)\n",
    "print(f\"F1 Score: {f1_scores}\")\n",
    "\n",
    "# Calculate RMSE for additional evaluation\n",
    "rmse_value = np.sqrt(mean_squared_error(y_test, predicted_pollutants))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
